import os
import ssl
import torch
import whisper
import warnings
import numpy as np
from pathlib import Path
from typing import Literal
from TTS.tts.configs.xtts_config import XttsConfig
from TTS.tts.models.xtts import Xtts
import argostranslate.package
import argostranslate.translate
import scipy.io.wavfile as wav_write

# ========== è¨­å®šå€ ==========
MODEL_SIZE = "tiny"
LANGUAGE_MODE: Literal["zh", "zh-en", "en", "ja"] = "zh-en"
DEVICE = "cpu"
LANGUAGE_PROMPTS = {
    "zh": {"language": "zh", "prompt": "è«‹è½‰éŒ„ä»¥ä¸‹ç¹é«”ä¸­æ–‡çš„å…§å®¹ï¼š"},
    "zh-en": {"language": "zh", "prompt": "è«‹è½‰éŒ„ä»¥ä¸‹å…§å®¹ï¼Œå¯èƒ½åŒ…å«ä¸­æ–‡å’Œè‹±æ–‡ï¼š"},
    "en": {"language": "en", "prompt": "Please transcribe the following English content:"},
    "ja": {"language": "ja", "prompt": "ä»¥ä¸‹ã®æ—¥æœ¬èªã®å†…å®¹ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ï¼š"}
}
FROM_CODE = "zh"
TO_CODE = "en"
TO_CODE_FINAL = "ja"
SPEAKER_WAV = "audio_files/zh-cn-sample.wav"
INPUT_FOLDER = "audio_files"
# ===========================

warnings.filterwarnings("ignore")

# è§£æ±º SSL å•é¡Œ
ssl._create_default_https_context = ssl._create_unverified_context

# ğŸŸ¦ Whisper èªéŸ³è½‰éŒ„
def transcribe_audio(model, audio_path: str, lang_config: dict) -> str:
    print(f"ğŸ§ è½‰éŒ„éŸ³è¨Šä¸­ï¼š{audio_path}")
    result = model.transcribe(audio_path, prompt=lang_config["prompt"], language=lang_config["language"])
    text = result['text']
    print(f"ğŸ“ è½‰éŒ„çµæœï¼š\n{text}")
    return text

# ğŸŸ¦ Argos Translate ç¿»è­¯
def translate_text(text: str, source_lang: str, target_lang: str) -> str:
    argostranslate.package.update_package_index()
    packages = argostranslate.package.get_available_packages()
    pkg = next((x for x in packages if x.from_code == source_lang and x.to_code == target_lang), None)
    if not pkg:
        raise Exception(f"âŒ æ‰¾ä¸åˆ°å¾ {source_lang} åˆ° {target_lang} çš„èªè¨€åŒ…")
    argostranslate.package.install_from_path(pkg.download())
    translated = argostranslate.translate.translate(text, source_lang, target_lang)
    print(f"ğŸŒ ç¿»è­¯ ({source_lang} â†’ {target_lang})ï¼š\n{translated}")
    return translated

# ğŸŸ¦ XTTS åˆæˆèªéŸ³
def synthesize_voice(text: str, speaker_wav: str, device: torch.device) -> None:
    torch_load_backup = torch.load

    def patched_torch_load(f, map_location=None, pickle_module=None, **kwargs):
        kwargs['weights_only'] = False
        return torch_load_backup(f, map_location, pickle_module, **kwargs)

    torch.load = patched_torch_load

    config = XttsConfig()
    config.load_json("XTTS-v2/config.json")

    model = Xtts.init_from_config(config)
    model.load_checkpoint(config, checkpoint_dir="XTTS-v2/", eval=True)
    model.to(device)

    if not os.path.exists(speaker_wav):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°åƒè€ƒéŸ³è¨Šï¼š{speaker_wav}")

    print("ğŸ—£ï¸ é–‹å§‹åˆæˆèªéŸ³...")
    outputs = model.synthesize(text, config, speaker_wav=speaker_wav, gpt_cond_len=3, language="ja")

    if "wav" in outputs:
        sr = outputs.get("sample_rate", 24000)
        wav_write.write("output.wav", sr, outputs["wav"])
        print("âœ… æˆåŠŸä¿å­˜éŸ³é »åˆ° output.wav")
    else:
        print("âŒ ç„¡æ³•æ‰¾åˆ°éŸ³è¨Šè³‡æ–™è¼¸å‡º")

    torch.load = torch_load_backup

# ğŸŸ¦ ä¸»æµç¨‹
def main():
    lang_config = LANGUAGE_PROMPTS[LANGUAGE_MODE]
    print(f"ğŸ”§ ä½¿ç”¨æ¨¡å‹ï¼š{MODEL_SIZE}, èªè¨€æ¨¡å¼ï¼š{LANGUAGE_MODE}")

    if not os.path.exists(INPUT_FOLDER):
        print(f"âš ï¸ æ‰¾ä¸åˆ°è³‡æ–™å¤¾ {INPUT_FOLDER}")
        return

    model = whisper.load_model(MODEL_SIZE, device=DEVICE)
    audio_files = [f for f in os.listdir(INPUT_FOLDER) if f.lower().endswith(('.mp3', '.wav', '.m4a', '.flac', '.mov', '.mp4', '.m4v'))]

    if not audio_files:
        print("âš ï¸ ç„¡éŸ³è¨Šæª”æ¡ˆå¯è™•ç†")
        return

    for file in audio_files:
        path = os.path.join(INPUT_FOLDER, file)
        try:
            transcription = transcribe_audio(model, path, lang_config)
            translated_en = translate_text(transcription, FROM_CODE, TO_CODE)
            translated_ja = translate_text(translated_en, TO_CODE, TO_CODE_FINAL)
            synthesize_voice(translated_ja, SPEAKER_WAV, torch.device("mps" if torch.backends.mps.is_available() else "cpu"))
        except Exception as e:
            print(f"âŒ è™•ç† {file} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

if __name__ == "__main__":
    main()
